{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ndo4ERqnwQOU"
   },
   "source": [
    "##### Copyright 2020 The TensorFlow Authors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YfIk2es3hJEd",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from IPython import display\n",
    "\n",
    "import glob\n",
    "import imageio\n",
    "import PIL\n",
    "import time\n",
    "import json\n",
    "from typing import List, Tuple, Dict, Optional\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "tfk = tf.keras\n",
    "tfkl = tf.keras.layers\n",
    "# tf.debugging.set_log_device_placement(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iYn4MdZnKCey"
   },
   "source": [
    "## Load the ACDC dataset\n",
    "\n",
    "Actually each patient in the ACDC dataset is a 4D volume (3 spatial dimension and one temporal one), where the myocard, richt and left ventricle are segmented in 2 time steps (end systolic (ES) and end diastolic (ED)). For an easier network structure and less memory requirements, the segmented time steps are sliced into 2D slices to be processed by the network. This was done beforehand and the resulting numpy vectors can be downloaded from [here](https://www.dropbox.com/sh/7z8kzt1hh2qxcse/AADn0XB8EPpj_TDqL1hvdo5Ba?dl=0). Fruther, a \"D reshaping to 256x256 pixels was done beforehand to save all images in one big array.\n",
    "\n",
    "__Question__: Why no preprocessing here?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = np.load(\"acdc_data/acdc_data_one_hot.npz\")\n",
    "train_images = dataset[\"train_imgs\"].astype(np.float32)\n",
    "train_labels = dataset[\"train_labels\"]\n",
    "test_images = dataset[\"test_imgs\"].astype(np.float32)\n",
    "test_labels = dataset[\"test_labels\"]\n",
    "\n",
    "with open('acdc_data/label_assignment.json') as f:\n",
    "    label_assignment = json.load(f)\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(train_images).shuffle(len(train_images))\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices(test_images).shuffle(len(test_images))\n",
    "label_assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Model\n",
    "\n",
    "__Question__: Why different upsampling and downsampling blocks compared to MNIST model here?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VGLbvBEmjK0a",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def downsampling_block(filters: int) -> tfk.Sequential:\n",
    "    return tfk.Sequential([\n",
    "        tfkl.Conv2D(filters=filters, kernel_size=3, strides=2, activation='relu'),\n",
    "        tfkl.Conv2D(filters=filters, kernel_size=3, strides=1, activation='relu', padding='same')\n",
    "    ])\n",
    "\n",
    "def upsampling_block(filters: int) -> tfk.Sequential:\n",
    "    return tfk.Sequential([\n",
    "        tfkl.Conv2DTranspose(filters=filters, kernel_size=3, strides=2, activation='relu', padding='same'),\n",
    "        tfkl.Conv2DTranspose(filters=filters, kernel_size=3, strides=1, activation='relu', padding='same')\n",
    "    ])\n",
    "\n",
    "class CVAE(tfk.Model):\n",
    "    \"\"\"Convolutional variational autoencoder.\"\"\"\n",
    "\n",
    "    def __init__(self, \n",
    "                 latent_dim: int, \n",
    "                 filters: List[int] = [32, 64],\n",
    "                 n_classes: int = 1,\n",
    "                 input_shape: Tuple[int, int, int] = (28, 28, 1)) -> None:\n",
    "        super().__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        self.n_classes = n_classes\n",
    "        enc_convs = [downsampling_block(f) for f in filters]\n",
    "        dec_convs = [upsampling_block(f) for f in filters]\n",
    "        self.encoder = tfk.Sequential([\n",
    "            tfkl.InputLayer(input_shape=input_shape),\n",
    "            *enc_convs,\n",
    "            tfkl.Flatten(),\n",
    "            # No activation\n",
    "            tfkl.Dense(latent_dim + latent_dim),\n",
    "        ])\n",
    "        \n",
    "        h = w = int(input_shape[0] / 2**len(filters))\n",
    "        self.decoder = tfk.Sequential([\n",
    "            tfkl.InputLayer(input_shape=(latent_dim,)),\n",
    "            tfkl.Dense(units=h*w*32, activation=tf.nn.relu),\n",
    "            tfkl.Reshape(target_shape=(h, w, 32)),\n",
    "            *dec_convs,\n",
    "            # No activation\n",
    "            tfkl.Conv2D(filters=n_classes, kernel_size=3, strides=1, padding='same'),\n",
    "        ])\n",
    "\n",
    "    @tf.function\n",
    "    def sample(self, eps: Optional[tf.Tensor] = None):\n",
    "        if eps is None:\n",
    "            eps = tf.random.normal(shape=(100, self.latent_dim))\n",
    "        return self.decode(eps, apply_sigmoid=True)\n",
    "\n",
    "    def encode(self, x: tf.Tensor) -> Tuple[tf.Tensor, ...]:\n",
    "        mean, logvar = tf.split(self.encoder(x), num_or_size_splits=2, axis=1)\n",
    "        eps = tf.random.normal(shape=mean.shape)\n",
    "        z = eps * tf.exp(logvar * .5) + mean\n",
    "        return z, mean, logvar\n",
    "\n",
    "    def decode(self, z: tf.Tensor, apply_sigmoid: bool = False) -> tf.Tensor:\n",
    "        logits = self.decoder(z)\n",
    "        if apply_sigmoid:\n",
    "            if self.n_classes == 1:\n",
    "                probs = tf.sigmoid(logits)\n",
    "            else:\n",
    "                probs = tf.math.argmax(tf.nn.softmax(logits), axis=-1)\n",
    "            return probs\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iWCn_PVdEJZ7",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def log_normal_pdf(sample: tf.Tensor, mean: tf.Tensor, logvar: tf.Tensor, raxis: int = 1) -> tf.Tensor:\n",
    "    log2pi = tf.math.log(2. * np.pi)\n",
    "    return tf.reduce_sum(\n",
    "        -.5 * ((sample - mean) ** 2. * tf.exp(-logvar) + logvar + log2pi),\n",
    "        axis=raxis)\n",
    "\n",
    "# Analytic KL for multivariate Gaussian\n",
    "def kl_divergence(mean: tf.Tensor, sd: tf.Tensor) -> tf.Tensor:\n",
    "    return - 0.5 * tf.reduce_sum(\n",
    "            1 + tf.math.log(tf.math.square(sd)) - tf.math.square(mean) - tf.math.square(sd),\n",
    "            axis=1)\n",
    "\n",
    "def compute_loss(model: tfk.Model, \n",
    "                 x: tf.Tensor, \n",
    "                 loss: str = \"cross_entropy\", \n",
    "                 analytic_kl: bool = False, \n",
    "                 beta: float = 1.) -> Tuple[tf.Tensor, ...]:\n",
    "\n",
    "    # forward pass\n",
    "    z, mean, logvar = model.encode(x)\n",
    "    x_logit = model.decode(z)\n",
    "    \n",
    "    # compute neg log likelihood\n",
    "    if loss == \"cross_entropy\":\n",
    "        cross_ent = tf.nn.softmax_cross_entropy_with_logits(logits=x_logit, labels=x)\n",
    "        logpx_z = -tf.reduce_sum(cross_ent, axis=[1, 2])#, 3])\n",
    "    elif loss == \"mse\":\n",
    "        logpx_z = tf.reduce_mean((x - x_logit)**2 / np.prod(x.shape), axis=[1, 2])#, 3])\n",
    "        \n",
    "    # compute kl divergence\n",
    "    if analytic_kl:\n",
    "        sd = tf.exp(logvar * .5)\n",
    "        kl_div = kl_divergence(mean, sd)\n",
    "    else:\n",
    "        logpz = log_normal_pdf(z, 0., 0.)\n",
    "        logqz_x = log_normal_pdf(z, mean, logvar)\n",
    "        kl_div = logpz - logqz_x\n",
    "    kl_div *= beta\n",
    "    \n",
    "    return -tf.reduce_mean(logpx_z + kl_div), logpx_z, kl_div\n",
    "\n",
    "@tf.function\n",
    "def train_step(model: tfk.Model, \n",
    "               x: tf.Tensor, \n",
    "               optimizer: tfk.optimizers.Optimizer, \n",
    "               loss: str = \"cross_entropy\",\n",
    "               analytic_kl: bool = False,\n",
    "               beta: float = 1.) -> Tuple[tf.Tensor, ...]:\n",
    "    \"\"\"Executes one training step and returns the loss.\n",
    "\n",
    "    This function computes the loss and gradients, and uses the latter to\n",
    "    update the model's parameters.\n",
    "    \"\"\"\n",
    "    with tf.GradientTape() as tape:\n",
    "        elbo, nll, kl_div = compute_loss(model, x)\n",
    "    gradients = tape.gradient(elbo, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    return elbo, nll, kl_div"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter\n",
    "\n",
    "__Question__: Why higher latent dim?\n",
    "\n",
    "__Question__: Why is cross entropy better suited as loss function in this case?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 20\n",
    "BATCH_SIZE = 32\n",
    "LR = 1e-3\n",
    "LATENT_DIM = 10\n",
    "LOSS = \"cross_entropy\"\n",
    "ANALYTIC_KL = True\n",
    "BETA = 1.\n",
    "FILTERS = [32, 64, 64]\n",
    "N_CLASSES = 4\n",
    "INPUT_SHAPE = (256, 256, N_CLASSES)\n",
    "\n",
    "train_dataset = train_dataset.batch(BATCH_SIZE)\n",
    "test_dataset = test_dataset.batch(BATCH_SIZE)\n",
    "num_examples_to_generate = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CVAE(LATENT_DIM, filters=FILTERS, input_shape=INPUT_SHAPE, n_classes=N_CLASSES)\n",
    "optimizer = tfk.optimizers.Adam(LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RmdVsmvhPxyy",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def from_one_hot(img_one_hot: np.ndarray) -> np.ndarray:\n",
    "    img = np.zeros(img_one_hot.shape[:-1])\n",
    "    for i in range(img_one_hot.shape[-1]):\n",
    "        img[img_one_hot[...,i].astype(bool)] = i\n",
    "    return img\n",
    "\n",
    "def plot_test_sample(test_sample: tf.Tensor) -> None:\n",
    "    if not isinstance(test_sample, np.ndarray):\n",
    "        test_sample = test_sample.numpy()\n",
    "    fig = plt.figure(figsize=(4, 4))\n",
    "    \n",
    "    for i in range(test_sample.shape[0]):\n",
    "        plt.subplot(4, 4, i + 1)\n",
    "        plt.imshow(test_sample[i, :, :], cmap='gray')\n",
    "        plt.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def generate_images(model: tfk.Model, test_sample: tf.Tensor) -> None:\n",
    "    z, mean, logvar = model.encode(test_sample)\n",
    "    predictions = model.sample(z)\n",
    "    plot_test_sample(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "swCyrbqQQ-Ri",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Pick a sample of the test set for generating output images\n",
    "assert BATCH_SIZE >= num_examples_to_generate\n",
    "for test_batch in test_dataset.take(1):\n",
    "    test_sample = test_batch[0:num_examples_to_generate, :, :, :]\n",
    "plot_test_sample(from_one_hot(test_sample.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2M7LmLtGEMQJ",
    "tags": []
   },
   "outputs": [],
   "source": [
    "generate_images(model, test_sample)\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    start_time = time.time()\n",
    "    for train_x in train_dataset:\n",
    "        elbo, nll, kl_div = train_step(model, train_x, optimizer, loss=LOSS, analytic_kl=ANALYTIC_KL, beta=BETA)\n",
    "    end_time = time.time()\n",
    "\n",
    "    for test_x in test_dataset:\n",
    "        elbo, nll, kl_div = compute_loss(model, test_x, loss=LOSS, analytic_kl=ANALYTIC_KL, beta=BETA)\n",
    "\n",
    "    display.clear_output(wait=False)\n",
    "    print(f'Epoch: {epoch}, Test set ELBO: {elbo.numpy():.2f}, time elapse for current epoch: {end_time - start_time:.2f}')\n",
    "    generate_images(model, test_sample)\n",
    "    \n",
    "    # model.save_weights('./checkpoints/acdc_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PeunRU6TSumT"
   },
   "source": [
    "### Display the structure of the latent space\n",
    "\n",
    "We explore the different clusters that are formed in latent space during training. Because our latent space has $\\mathrm{dim} \\geq 2$, we must use a dimensionality reduction technique to project to 2 dimensions for which ussually t-SNE is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('./checkpoints/acdc_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "def plot_latent_space(model: tfk.Model, test_images: np.ndarray, test_labels: np.ndarray, label_assignment: Optional[Dict[int, str]] = None) -> None:\n",
    "    zs = np.array([model.encode(test_x[None,...,None])[0].numpy()[0].tolist() for test_x in test_images])\n",
    "    if zs.shape[-1] > 2: # check if latent_dim > 2 -> dimensionality reduction with tsne for plotting purposes\n",
    "        tsne = TSNE()\n",
    "        zs = tsne.fit_transform(zs)\n",
    "    zs = {n: zs[test_labels == n] for n in range(int(test_labels.max() + 1))}\n",
    "    for n, zs_n in zs.items():\n",
    "        label = label_assignment[str(n)] if label_assignment is not None else n\n",
    "        plt.scatter(zs_n[:,0], zs_n[:,1], label=label)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_latent_space(model, test_images, test_labels, label_assignment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "cvae.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "vae-tutorial",
   "language": "python",
   "name": "vae-tutorial"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
